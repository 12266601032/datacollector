
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="By default, the Hadoop FS destination creates a complex set of directories for output files and late record files, keeping files open for writing based on stage configuration. That's great, but once ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="concept"></meta><meta name="DC.Title" content="Case Study: Output File Management"></meta><meta name="DC.Relation" scheme="URI" content="../Event_Handling/EventHandling-Title.html"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="concept_d1q_xl4_lx"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Case Study: Output File Management</title><!--  Generated with Oxygen version 17.1, build number 2016020417.  --><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script><!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
--></head>
<body onload="highlightSearchTerm()" class="frmBody" id="concept_d1q_xl4_lx">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Event_Handling/EventHandling-Title.html" title="Event Handling">Event Handling</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Event_Handling/EventHandling-Title.html" title="Event Handling"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Event Handling</span></a></span>  </div></td></tr></tbody></table>

    <h1 class="title topictitle1">Case Study: Output File Management</h1>

    <div class="body conbody">
        <p class="p">By default, the Hadoop FS destination creates a
            complex set of directories for output files and late record files, keeping files open
            for writing based on stage configuration. That's great, but once the files are complete,
            you'd like the files moved to a different location. And while you're at it, it would be
            nice to set the permissions for the written files. </p>

        <p class="p">So what do you do? </p>

        <p class="p">Add an event stream to the pipeline to manage output files when the Hadoop FS destination
            is done writing them. </p>

        <p class="p">Here's a pipeline that reads from a database using JDBC, performs some processing, and
            writes to HDFS:</p>

        <p class="p"><img class="image" id="concept_d1q_xl4_lx__image_y1d_zm4_lx" src="../Graphics/Event-Move-BasicPipe.png" height="102" width="651"></img></p>

        <ol class="ol" id="concept_d1q_xl4_lx__ol_fvh_5m4_lx">
            <li class="li">To add an event stream, first configure Hadoop FS to generate events:<p class="p">On the
                        <span class="keyword wintitle">General</span> tab of the Hadoop FS destination, select the
                        <span class="ph uicontrol">Produce Events</span> property. </p>
<p class="p">Now, the event output
                    stream becomes available, and Hadoop FS generates an event record each time it
                    closes an output file. The Hadoop FS event record includes fields for the file
                    name, path, and size.</p>
<p class="p"><img class="image" id="concept_d1q_xl4_lx__image_n5q_5p4_lx" src="../Graphics/Event-Move-HDFS.png" height="299" width="619"></img></p>
</li>

            <li class="li">Connect the Hadoop FS event output stream to a HDFS File Metadata executor.<p class="p">Now,
                    each time the HDFS File Metadata executor receives an event, it triggers the
                    tasks that you configure it to run.</p>
<p class="p"><img class="image" id="concept_d1q_xl4_lx__image_x4w_kq4_lx" src="../Graphics/Event-Move-HDFSMetadata.png" height="172" width="675"></img></p>
</li>

            <li class="li">Configure the HDFS File Metadata executor to move the files to the directory that
                you want and set the permissions for the file.<p class="p">In the HDFS File Metadata executor,
                    configure the HDFS configuration details on the <span class="keyword wintitle">HDFS</span> tab.
                    Then, on the <span class="keyword wintitle">Tasks</span> tab, configure the changes that you want
                    to make. </p>
<p class="p">In this case, you want to move files to
                        <span class="ph filepath">/new/location</span>, and set the file permissions to 0440 to
                    allow the user and group read access to the files:</p>
<p class="p"><img class="image" id="concept_d1q_xl4_lx__image_uk1_l1c_tx" src="../Graphics/Event-Move-FileMetadata-props.png" height="381" width="703"></img></p>
</li>

        </ol>

        <p class="p">With this event stream added to the pipeline, each time the Hadoop FS destination closes
            a file, it generates an event record. When the HDFS File Metadata executor receives the
            event record, it moves the file and sets the file permissions. No muss, no fuss.</p>

    </div>

<div class="related-links"></div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Event_Handling/EventHandling-Title.html" title="Event Handling"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Event Handling</span></a></span>  </div><div class="footer"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>

<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en-us" lang="en-us">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />        
      <meta name="copyright" content="(C) Copyright 2005" /><meta name="DC.rights.owner" content="(C) Copyright 2005" /><meta name="DC.Type" content="concept" /><meta name="DC.Title" content="Destinations" /><meta name="abstract" content="A destination stage represents the target for a pipeline. You can use one or more destinations in a pipeline." /><meta name="description" content="A destination stage represents the target for a pipeline. You can use one or more destinations in a pipeline." /><meta name="DC.Relation" scheme="URI" content="../Destinations/Destinations-title.html" /><meta name="DC.Format" content="XHTML" /><meta name="DC.Identifier" content="concept_hpr_twm_jq" /><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Destinations</title><!--  Generated with Oxygen version 18.1, build number 2016112217.  --><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css" /><link rel="stylesheet" type="text/css" href="../skin.css" /><script type="text/javascript"><!--
            
            var prefix = "../index.html";
            
            --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.11.3.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
</head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td style="width:75%;"><span class="topic_breadcrumb_links"><span class="topic_breadcrumb_link"><a class="navheader_parent_path" href="../Destinations/Destinations-title.html" title="Destinations">Destinations</a></span></span></td><td><span id="topic_navigation_links" class="navheader">
<span class="navparent"><a class="link" href="../Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </span></td></tr></tbody></table>
<div class="nested0" id="concept_hpr_twm_jq">
 <h1 class="title topictitle1">Destinations</h1>

 
 <div class="body conbody"><p class="shortdesc">A destination stage represents the target for a pipeline. You can use one or more
    destinations in a pipeline.</p>

  <div class="p">You can use the following
      types of destinations in a pipeline: <ul class="ul" id="concept_hpr_twm_jq__ul_mxz_jxm_jq">
        <li class="li">Amazon S3 - Writes data to Amazon S3. </li>

        <li class="li">Azure Data Lake Store - Writes data to the Azure Data Lake Store.</li>

        <li class="li">Cassandra - Writes data to a Cassandra cluster.</li>

        <li class="li">Elasticsearch - Writes data to an Elasticsearch cluster.</li>

        <li class="li">Flume - Writes data to a Flume source.</li>

        <li class="li">Google Bigtable - Writes data to Google Cloud Bigtable.</li>

        <li class="li">Hadoop FS - Writes data to the Hadoop Distributed File System (HDFS).</li>

        <li class="li">HBase - Writes data to an HBase cluster.</li>

        <li class="li">Hive Metastore - Creates and updates Hive tables as needed.</li>

        <li class="li">Hive Streaming - Writes data to Hive.</li>

        <li class="li">InfluxDB - Writes data to InfluxDB.</li>

        <li class="li">JDBC Producer - Writes data to JDBC.</li>

        <li class="li">Kafka Producer - Writes data to a Kafka cluster.</li>

        <li class="li">Kinesis Firehose - Writes data to a Kinesis Firehose delivery stream.</li>

        <li class="li">Kinesis Producer - Writes data to Kinesis Streams.</li>

        <li class="li">Kudu - Writes data to Kudu.</li>

        <li class="li">Local FS - Writes data to a local file system. </li>

        <li class="li">MapR DB - Writes data to MapR DB.</li>

        <li class="li">MapR FS - Writes data to MapR FS.</li>

        <li class="li">MapR Streams Producer - Writes data to MapR Streams.</li>

        <li class="li">MongoDB - Writes data to MongoDB.</li>

        <li class="li">Rabbit MQ Producer - Writes data to RabbitMQ.</li>

        <li class="li">Redis - Writes data to Redis.</li>

        <li class="li">Salesforce - Writes data to Salesforce.</li>

        <li class="li">SDC RPC - Passes data to an SDC RPC origin in an SDC RPC pipeline.</li>

        <li class="li">Solr - Writes data to a Solr node or cluster.</li>

        <li class="li">To Error - Passes records to the pipeline for error handling.</li>

        <li class="li">Trash - Removes records from the pipeline.</li>

        <li class="li">Wave Analytics - Writes data to Salesforce Wave Analytics.</li>

      </ul>
To help create or test pipelines, you can use the following development destination:<ul class="ul" id="concept_hpr_twm_jq__ul_wvk_p3f_lx">
        <li class="li">To Event</li>

      </ul>
</div>

    <p class="p">For more information, see <a class="xref" href="../Pipeline_Design/DevStages.html#concept_czx_ktn_ht">Development Stages</a>.</p>

 </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_lmn_gdc_1w">
    <h2 class="title topictitle2">Record Header Attributes for Record-Based Writes</h2>

    <div class="body conbody">
        <p class="p">Destinations can use information in record header
            attributes to write data. Destinations that write Avro data can use Avro schemas in the
            record header. The Hadoop FS and MapR FS destinations can use record header attributes
            to determine the directory to write to and when to roll a file as part of the Hive Drift
            Solution. For more information, see <a class="xref" href="../Hive_Drift_Solution/HiveDriftSolution_title.html#concept_phk_bdf_2w">Hive Drift Solution: Ingesting Drifting Data into Hive</a>.</p>

        <p class="p">To use a record header attribute, configure the destination to use the header attribute
            and ensure that the records include the header attribute.</p>

        <p class="p"><span class="ph">The Hive Metadata processor automatically generates record
                        header attributes for Hadoop FS and MapR FS to use as part of the Hive Drift
                        Solution. For all other destinations, you can use the Expression Evaluator
                        to add record header attributes.</span>
        </p>

        <div class="p">You can use the following record header attributes in destinations:
            <dl class="dl">
                
                    <dt class="dt dlterm">targetDirectory attribute in the Hadoop FS, Local FS, and MapR FS
                        destinations</dt>

                    <dd class="dd">The targetDirectory record header attribute defines the directory where the
                        record is written. If the directory does not exist, the destination creates
                        the directory. The targetDirectory header attribute replaces the Directory
                        Template property in the destination.</dd>

                    <dd class="dd">When you use targetDirectory to provide the directory, the time basis
                        configured for the destination is used only for determining whether a record
                        is late. Time basis is not used to determine the output directories to
                        create or to write records to directories.</dd>

                    <dd class="dd">To use the targetDirectory header attribute, on the
                            <span class="keyword wintitle">Output</span> tab, select <span class="ph uicontrol">Directory in
                            Header</span>.</dd>

                
                
                    <dt class="dt dlterm">avroSchema attribute in destinations that write Avro data</dt>

                    <dd class="dd">The avroSchema header attribute defines the Avro schema for the record. When
                        you use this header attribute, you cannot define an Avro schema to use in
                        the destination. </dd>

                    <dd class="dd">To use the avroSchema header attribute, on the <span class="keyword wintitle">Data
                            Format</span> tab, select the <span class="ph uicontrol">Avro</span> data
                        format, and then for the <span class="ph uicontrol">Avro Schema Location</span>
                        property, select <span class="ph uicontrol">In Record Header</span>.</dd>

                
                
                    <dt class="dt dlterm">roll attribute in the Hadoop FS, Local FS, and MapR FS destinations</dt>

                    <dd class="dd">The roll attribute, when present in the record header, triggers a roll of
                        the file. </dd>

                    <dd class="dd">You can define the name of the roll header attribute. When you use the Hive
                        Metadata processor to generate the roll header attribute, use the default
                        "roll" attribute name. When you use an Expression Evaluator, use the name of
                        the roll attribute that you defined in the processor.</dd>

                    <dd class="dd">To use a roll header attribute, on the <span class="keyword wintitle">Output</span> tab,
                        select <span class="ph uicontrol">Use Roll Attribute</span> and define the name of the
                        attribute. </dd>

                
            </dl>
</div>

    </div>

<div class="topic concept nested2" id="concept_th5_3zj_mw">
    <h3 class="title topictitle3">Generating Record Header Attributes</h3>

    <div class="body conbody">
        <p class="p">You can
            use the Hive Metadata processor or the Expression Evaluator to generate record header
            attributes for record-based writes. <span class="ph">The Hive Metadata processor automatically generates record
                        header attributes for Hadoop FS and MapR FS to use as part of the Hive Drift
                        Solution. For all other destinations, you can use the Expression Evaluator
                        to add record header attributes.</span></p>

        <div class="p">To use the Expression Evaluator, you must generate record header attributes as expected
            by the destination. Use the following guidelines to generate record header attributes
            with the Expression Evaluator:<dl class="dl">
                
                    <dt class="dt dlterm">Generating the target directory with the Expression Evaluator</dt>

                    <dd class="dd">When using the Expression Evaluator to generate the target directory, note
                        the following details:</dd>

                    <dd class="dd">
                        <ul class="ul" id="concept_th5_3zj_mw__ul_i1l_xyj_mw">
                            <li class="li">The destination expects the directory in a header attribute named
                                "targetDirectory".</li>

                            <li class="li">
                                <p class="p">The destination uses the directory exactly as written in the
                                    targetDirectory header attribute. Unlike directory templates,
                                    the directory specified in the targetDirectory attribute should
                                    not include any components that require evaluation, such as
                                    constants, variables, or runtime properties. </p>

                            </li>

                            <li class="li">
                                <p class="p">When you define the expression that evaluates to a directory, you
                                    can use any valid component, including expressions that evaluate
                                    data in the record. </p>

                            </li>

                        </ul>

                    </dd>

                    <dd class="dd">
                        <p class="p">For example, you want to write records to different directories based on
                            the <span class="ph">Data
                  Collector</span> that runs the pipeline, and the region and store ID where the
                            transaction took place. You can set up a runtime resource named DIR that
                            defines the base for the directory and define DIR for each <span class="ph">Data
                  Collector</span> that runs the pipeline. Then, you can use the following expression in
                            the Expression Evaluator to define the targetDirectory attribute: </p>

                        <pre class="pre">${runtime:conf('DIR')/transactions/${record.value('/region')}/${record.value('/storeID')}</pre>

                    </dd>

                
                
                    <dt class="dt dlterm">Generating the Avro schema with the Expression Evaluator</dt>

                    <dd class="dd">When using the Expression Evaluator to generate the Avro schema, note the
                        following details: <ul class="ul" id="concept_th5_3zj_mw__ul_kx1_4ql_nw">
                            <li class="li">The destination expects the Avro schema in a header attribute named
                                "avroSchema".</li>

                            <li class="li">Use the standard Avro schema format, for example:
                                <pre class="pre codeblock">{"type":"record","name":"table_name","namespace":"database_name",
"fields":[{"name":"int_val","type":["null","int"],"default":null},
{"name":"str_val","type":["null","string"],"default":null}]}</pre>
</li>

                            <li class="li">The database name and table name must be included in the Avro
                                schema.</li>

                        </ul>
</dd>

                    <dd class="dd">
                        <div class="note tip"><span class="tiptitle">Tip:</span> You might use an Avro schema generator to help generate the
                            Avro schema. </div>

                    </dd>

                
                
                    <dt class="dt dlterm">Generating the roll attribute with the Expression Evaluator</dt>

                    <dd class="dd">When using the Expression Evaluator to generate the roll attribute, note the
                        following details: <ul class="ul" id="concept_th5_3zj_mw__ul_a23_hnc_pw">
                            <li class="li">Use any name for the attribute and specify the attribute name in the
                                destination. </li>

                            <li class="li">Configure an expression that defines when to roll files.</li>

                        </ul>
</dd>

                
            </dl>
</div>

        <div class="p">To define a record header attribute in the Expression Evaluator, perform the following
                steps:<ol class="ol" id="concept_th5_3zj_mw__ol_jww_k31_cw">
                <li class="li">On the <span class="keyword wintitle">Expressions</span> tab of the Expression Evaluator, specify
                    the <span class="ph uicontrol">Header Attribute</span> name. <p class="p">To generate a target
                        directory, use <samp class="ph codeph">targetDirectory</samp>. </p>
<p class="p">To generate an Avro
                        schema, use <samp class="ph codeph">avroSchema</samp>.</p>
<p class="p">You can use any name for a
                        roll indicator header attribute.</p>
</li>

                <li class="li">For the <span class="ph uicontrol">Header Attribute Expression</span>, define the
                    expression that evaluates to the information you want the destination to use.
                </li>

            </ol>
</div>

    </div>

</div>
</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </div><div class="footer" id="webhelp_copyright_information"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>
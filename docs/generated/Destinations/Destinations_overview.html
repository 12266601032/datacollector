
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="A destination stage represents the target for a pipeline. You can use one or more destinations in a pipeline. You can use the following types of destinations in a pipeline: Cassandra - Writes data to ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="concept"></meta><meta name="DC.Title" content="Destinations"></meta><meta name="abstract" content="A destination stage represents the target for a pipeline. You can use one or more destinations in a pipeline."></meta><meta name="description" content="A destination stage represents the target for a pipeline. You can use one or more destinations in a pipeline."></meta><meta name="DC.Relation" scheme="URI" content="../Destinations/Destinations-title.html"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="concept_hpr_twm_jq"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Destinations</title><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script></head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Destinations/Destinations-title.html" title="Destinations">Destinations</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="concept_hpr_twm_jq">
 <h1 class="title topictitle1">Destinations</h1>

 
 <div class="body conbody"><p class="shortdesc">A destination stage represents the target for a pipeline. You can use one or more
    destinations in a pipeline.</p>

  <div class="p">You can use the following
      types of destinations in a pipeline: <ul class="ul" id="concept_hpr_twm_jq__ul_mxz_jxm_jq">
        <li class="li">Cassandra - Writes data to a Cassandra cluster.</li>

        <li class="li">Elasticsearch - Writes data to an Elasticsearch cluster.</li>

        <li class="li">Flume - Writes data to a Flume source.</li>

        <li class="li">Hadoop FS - Writes data to the Hadoop Distributed File System (HDFS).</li>

        <li class="li">HBase - Writes data to an HBase cluster.</li>

        <li class="li">Kafka Producer - Writes data to a Kafka cluster.</li>

        <li class="li">Kinesis Producer - Writes data to a Kinesis cluster.</li>

        <li class="li">Solr - Writes data to a Solr node or cluster.</li>

        <li class="li">To Error - Passes records to the pipeline for error handling.</li>

        <li class="li">Trash - Removes records from the pipeline.</li>

      </ul>
</div>

 </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_h4y_ycm_xs">
 <h2 class="title topictitle2">LZO and Snappy Compression</h2>

 
 <div class="body conbody"><p class="shortdesc">You can use LZO or Snappy compression for Hadoop FS and HBase destinations. Or you can
  use Snappy compression for Cassandra. </p>

  <p class="p">Note that due to JVM limitations, you cannot use Snappy for Cassandra and the Hadoop
   destinations - you can use Snappy with Cassandra or with Hadoop FS and HBase. </p>

  <p class="p">In addition, JVM limitations allow you to use LZO or Snappy compression with only one version
   of Hadoop FS and HBase. The Hadoop FS and HBase destinations are installed together in a library
   version. If you installed multiple libraries, resulting in multiple versions of the destinations,
   make sure to configure the <span class="ph">Data
                  Collector</span> to use
   compression with the library that you want to use. </p>

 </div>

<div class="topic concept nested2" id="concept_a15_fcm_xs">
 <h3 class="title topictitle3">Enabling LZO and Snappy Compression</h3>

 <div class="body conbody">
  <div class="p">The steps to enable compression differ based on the compression type and destinations that you
      want to use them with:<dl class="dl">
        
          <dt class="dt dlterm">Using Snappy with the Hadoop FS or HBase destinations</dt>

          <dd class="dd">You can use Snappy with one version of Hadoop FS or HBase. If you enable Snappy for
            Hadoop FS and HBase, do not enable it for Cassandra. </dd>

          <dd class="dd">To enable Snappy for Hadoop FS and HBase, perform the following steps:</dd>

          <dd class="dd">
            <ol class="ol" id="concept_a15_fcm_xs__ol_ufy_42m_xs">
              <li class="li">Verify the location of the libsnappy.so file.<p class="p">With the Hadoop installation, the
                  libsnappy.so file is generally installed in the following directory: <span class="ph filepath">
                    /usr/lib/hadoop/lib/native/</span>. </p>
<p class="p">If the file is not installed at
                  this location, see the documentation for your Hadoop distribution for the location
                  of the file or instructions on how to install the file. For details, see the
                  documentation for your Hadoop distribution.</p>
If you have two versions of Hadoop
                FS and HBase installed, make sure to locate the file for the version you want to
                use. </li>

              <li class="li">In the <span class="ph">Data
                  Collector</span>
                environment file, add the libsnappy.so directory to the SDC_JAVA_OPTS environment
                variable. <p class="p">For information about the SDC_JAVA_OPTS environment variable, see <a class="xref" href="../Install_Config/DCEnvironmentConfig.html#concept_vrx_4fg_qr" title="You can define the Java heap size used by the Data Collector. By default, the Data Collector Java heap size is 1024 MB. When you use the Data Collector with Java 7, you can define the Java Permanent Generation size, also known as the PermGen size.">Java Configuration Options</a>.</p>
</li>

            </ol>

          </dd>

        
        
          <dt class="dt dlterm">Using LZO with the Hadoop FS or HBase destinations</dt>

          <dd class="dd">You can use LZO with one version of Hadoop FS or HBase. </dd>

          <dd class="dd">To enable LZO for Hadoop FS and HBase, perform the following steps:<ol class="ol" id="concept_a15_fcm_xs__ol_l3s_fjm_xs">
              <li class="li">If necessary, install the Hadoop LZO native library. <p class="p">If you have two versions
                  of Hadoop FS and HBase installed, make sure you install the version that you want
                  to use. See the documentation for your Hadoop distribution for details. </p>
</li>

              <li class="li">In the <span class="ph">Data
                  Collector</span>
                environment file, add the Hadoop LZO directory to the SDC_JAVA_OPTS environment
                variable.</li>

            </ol>
<p class="p">For information about the SDC_JAVA_OPTS environment variable, see <a class="xref" href="../Install_Config/DCEnvironmentConfig.html#concept_vrx_4fg_qr" title="You can define the Java heap size used by the Data Collector. By default, the Data Collector Java heap size is 1024 MB. When you use the Data Collector with Java 7, you can define the Java Permanent Generation size, also known as the PermGen size.">Java Configuration Options</a>.</p>
</dd>

        
        
          <dt class="dt dlterm">Using Snappy with the Cassandra destination</dt>

          <dd class="dd">
            
          </dd>

        
      </dl>
</div>

 </div>

</div>
</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Destinations/Destinations-title.html" title="Destinations"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Destinations</span></a></span>  </div><div class="footer"><div> </div><!-- Â© <a href="http://creativecommons.org/licenses/by-nc/4.0/legalcode">CC BY-NC 4.0.</a> StreamSets, 2015. --></div>
</body>
</html>
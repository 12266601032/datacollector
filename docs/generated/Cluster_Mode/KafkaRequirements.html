
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="Cluster mode pipelines that read from a Kafka cluster have the following minimum requirements: Component Minimum Requirement Spark Streaming Spark version 1.3 through 1.6 Apache Kafka Spark Streaming ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="task"></meta><meta name="DC.Title" content="Kafka Requirements"></meta><meta name="DC.Relation" scheme="URI" content="../Cluster_Mode/ClusterPipelines_title.html"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="task_gmd_msw_yr"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Kafka Requirements</title><!--  Generated with Oxygen version 17.1, build number 2016020417.  --><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script><!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
--></head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines">Cluster Pipelines</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Cluster Pipelines</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="task_gmd_msw_yr">
    <h1 class="title topictitle1">Kafka Requirements</h1>

    <div class="body taskbody">
        <div class="section context">
            <div class="p">Cluster mode pipelines that read from a Kafka cluster
                have the following minimum requirements: 
<div class="tablenoborder"><table cellpadding="4" cellspacing="0" summary="" id="task_gmd_msw_yr__table_agw_5pn_zw" class="table" frame="border" border="1" rules="all">
                        
                        
                        <thead class="thead" align="left">
                            <tr class="row">
                                <th class="entry" valign="top" width="33.33333333333333%" id="d23979e35">Component</th>

                                <th class="entry" valign="top" width="66.66666666666666%" id="d23979e38">Minimum Requirement</th>

                            </tr>

                        </thead>

                        <tbody class="tbody">
                            <tr class="row">
                                <td class="entry" valign="top" width="33.33333333333333%" headers="d23979e35 ">Spark Streaming</td>

                                <td class="entry" valign="top" width="66.66666666666666%" headers="d23979e38 ">Spark version 1.3 through 1.6</td>

                            </tr>

                            <tr class="row">
                                <td class="entry" valign="top" width="33.33333333333333%" headers="d23979e35 ">Apache Kafka</td>

                                <td class="entry" valign="top" width="66.66666666666666%" headers="d23979e38 ">Spark Streaming on YARN requires a Cloudera or Hortonworks
                                    distribution of an Apache Kafka cluster. <p class="p">Spark Streaming on
                                        Mesos requires Apache Kafka on Apache Mesos.</p>
</td>

                            </tr>

                        </tbody>

                    </table>
</div>
</div>

            <div class="note note"><span class="notetitle">Note:</span> When you add a partition to the Kafka topic, restart the pipeline to enable the
                    <span class="ph">Data
                  Collector</span> to generate a new worker to read from the new partition. </div>

        </div>

    </div>

<div class="related-links"></div>
<div class="topic task nested1" id="task_hhk_bfv_cy">
    <h2 class="title topictitle2">Configuring Cluster YARN Streaming for Kafka</h2>

    <div class="body taskbody">
        <div class="section context">
            <p class="p">Complete
                the following steps to configure a cluster pipeline to read from a Kafka cluster on
                YARN:</p>

        </div>

        <ol class="ol steps"><li class="li step stepexpand">
                <span class="ph cmd">Verify the installation of Kafka, Spark Streaming, and YARN as the cluster
                    manager.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Install the <span class="ph">Data
                  Collector</span> on a Spark and YARN gateway node.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">If necessary, specify the location of the spark-submit script.</span>
                <div class="itemgroup info">The <span class="ph">Data
                  Collector</span> assumes that the spark-submit script, used to submit job requests to Spark
                    Streaming, is located in the following directory:
                    <pre class="pre codeblock">/usr/bin/spark-submit</pre>
If the script is not in this
                    directory, use the SPARK_SUBMIT_YARN_COMMAND environment variable to define the
                    location of the script.</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To enable <span class="ph">Data
                  Collector</span> to submit YARN jobs, perform one of the following tasks:</span>
                <div class="itemgroup info">
                    <ul class="ul" id="task_hhk_bfv_cy__ul_qf3_r1j_cy">
                        <li class="li">On YARN, set the min.user.id to a value equal to or lower than the user
                            ID associated with the <span class="ph">Data
                  Collector</span> user ID, typically named "sdc".</li>

                        <li class="li">On YARN, add the <span class="ph">Data
                  Collector</span> user name, typically "sdc", to the allowed.system.users
                            property.</li>

                    </ul>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On YARN, verify that the Spark logging level is set to a severity of INFO or
                    lower.</span>
                <div class="itemgroup info">YARN sets the Spark logging level to INFO by default. To change the logging
                        level:<ol class="ol" type="a" id="task_hhk_bfv_cy__ol_tzg_ggl_px">
                              <li class="li">Edit the log4j.properties file, located in the following
                                    directory:
                                    <pre class="pre codeblock">&lt;spark-home&gt;/conf/log4j.properties</pre>
</li>

                              <li class="li">Set the <span class="ph uicontrol">log4j.rootCategory</span> property to a
                                    severity of INFO or lower, such as DEBUG or TRACE.</li>

                        </ol>
</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">If YARN is configured to use Kerberos authentication, configure <span class="ph">Data
                  Collector</span> to use Kerberos authentication. </span>
                <div class="itemgroup info">When you configure Kerberos authentication for <span class="ph">Data
                  Collector</span>, you enable <span class="ph">Data
                  Collector</span> to use Kerberos and define the principal and keytab. <p class="p">When Kerberos is
                        enabled for <span class="ph">Data
                  Collector</span>, <span class="ph">Data
                  Collector</span> automatically uses the Kerberos principal and keytab to connect to any
                        YARN cluster that uses Kerberos. </p>
<p class="p">For more information, see <a class="xref" href="../Install_Config/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Enabling Kerberos Authentication</a>.</p>
</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the pipeline properties, on the <span class="keyword wintitle">General</span> tab, set the
                        <span class="ph uicontrol">Execution Mode</span> property to <span class="ph uicontrol">Cluster YARN
                        Streaming</span>.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Cluster</span> tab, enter the required properties for
                    YARN.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the pipeline, use a Kafka Consumer origin.</span>
                <div class="itemgroup info">If necessary, select a cluster mode stage library on the
                        <span class="keyword wintitle">General</span> tab of the origin. </div>
            </li>
</ol>

    </div>

    <div class="related-links"><div class="relinfo"><strong>Related information</strong><br xmlns="http://www.w3.org/1999/xhtml" />
<div class="related_link"><a class="navheader_parent_path" href="../Pipeline_Configuration/ConfiguringAPipeline.html#task_xlv_jdw_kq" title="Configure a pipeline to define the stream of data. After you configure the pipeline, you can start the pipeline.">Configuring a Pipeline</a></div>
<div class="related_link"><a class="navheader_parent_path" href="../Origins/KConsumer.html#concept_msz_wnr_5q" title="The Kafka Consumer origin reads data from an Apache Kafka cluster.">Kafka Consumer</a></div>
</div>
</div>
</div>
<div class="topic task nested1" id="task_kf1_fgv_cy">
    <h2 class="title topictitle2">Configuring Cluster Mesos Streaming for Kafka</h2>

    <div class="body taskbody">
        <div class="section context">
            <p class="p">Complete
                the following steps to configure a cluster pipeline to read from a Kafka cluster on
                Mesos:</p>

        </div>

        <ol class="ol steps" id="task_kf1_fgv_cy__steps_jhp_wgv_cy"><li class="li step stepexpand">
                <span class="ph cmd">Verify the installation of Kafka, Spark Streaming, and Mesos as the cluster
                    manager.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Install the <span class="ph">Data
                  Collector</span> on a Spark and Mesos gateway node.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">If necessary, specify the location of the spark-submit script.</span>
                <div class="itemgroup info">The <span class="ph">Data
                  Collector</span> assumes that the spark-submit script, used to submit job requests to Spark
                    Streaming, is located in the following directory:
                    <pre class="pre codeblock">/usr/bin/spark-submit</pre>
If the script is not in this
                    directory, use the SPARK_SUBMIT_MESOS_COMMAND environment variable to define the
                    location of the script.</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the pipeline properties, on the <span class="keyword wintitle">General</span> tab, set the
                        <span class="ph uicontrol">Execution Mode</span> property to <span class="ph uicontrol">Cluster Mesos
                        Streaming</span>.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Cluster</span> tab, enter the required properties for
                    Mesos.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the pipeline, use a Kafka Consumer origin for cluster mode.</span>
                <div class="itemgroup info">If necessary, select a cluster mode stage library on the
                        <span class="keyword wintitle">General</span> tab of the origin. </div>
            </li>
</ol>

    </div>

    <div class="related-links"><div class="relinfo"><strong>Related information</strong><br xmlns="http://www.w3.org/1999/xhtml" />
<div class="related_link"><a class="navheader_parent_path" href="../Pipeline_Configuration/ConfiguringAPipeline.html#task_xlv_jdw_kq" title="Configure a pipeline to define the stream of data. After you configure the pipeline, you can start the pipeline.">Configuring a Pipeline</a></div>
<div class="related_link"><a class="navheader_parent_path" href="../Origins/KConsumer.html#concept_msz_wnr_5q" title="The Kafka Consumer origin reads data from an Apache Kafka cluster.">Kafka Consumer</a></div>
</div>
</div>
</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Cluster Pipelines</span></a></span>  </div><div class="footer"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>
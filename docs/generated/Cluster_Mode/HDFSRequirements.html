
<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="Cluster mode pipelines that read from HDFS require the Cloudera distribution of Hadoop (CDH) or Hortonworks Data Platform (HDP). Complete the following steps to configure a cluster mode pipeline to ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="task"></meta><meta name="DC.Title" content="HDFS Requirements"></meta><meta name="DC.Relation" scheme="URI" content="../Cluster_Mode/ClusterPipelines_title.html"></meta><meta name="DC.Relation" scheme="URI" content="../Pipeline_Configuration/ConfiguringAPipeline.html#task_xlv_jdw_kq"></meta><meta name="DC.Relation" scheme="URI" content="../Origins/HadoopFS-origin.html#concept_lw2_tnm_vs"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="task_akz_w5b_ws"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>HDFS Requirements</title><!--  Generated with Oxygen version 17.1, build number 2016020417.  --><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/skins/skin.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script><!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
--></head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines">Cluster Pipelines</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Cluster Pipelines</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="task_akz_w5b_ws">
    <h1 class="title topictitle1">HDFS Requirements</h1>

    <div class="body taskbody">
        <div class="section context">
            <p class="p">Cluster mode pipelines that read from HDFS require the
                Cloudera distribution of Hadoop (CDH) or Hortonworks Data Platform (HDP).</p>

            <p class="p">Complete the following steps to configure a cluster mode pipeline to read from HDFS: </p>

        </div>

        <ol class="ol steps" id="task_akz_w5b_ws__steps_ldn_rhw_cy"><li class="li step stepexpand">
                <span class="ph cmd">Verify the installation of HDFS and YARN.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">Install <span class="ph">Data
                  Collector</span> on a YARN gateway node.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">To enable <span class="ph">Data
                  Collector</span> to submit YARN jobs, perform one of the following tasks:</span>
                <div class="itemgroup info">
                    <ul class="ul" id="task_akz_w5b_ws__ul_qf3_r1j_cy">
                        <li class="li">On YARN, set the min.user.id to a value equal to or lower than the user
                            ID associated with the <span class="ph">Data
                  Collector</span> user ID, typically named "sdc".</li>

                        <li class="li">On YARN, add the <span class="ph">Data
                  Collector</span> user name, typically "sdc", to the allowed.system.users
                            property.</li>

                        <li class="li">After you create the pipeline, specify a Hadoop FS user in the Hadoop FS
                            origin. <p class="p">For the Hadoop FS User property, enter a user with an ID that
                                is higher than the min.user.id property, or with a user name that is
                                listed in the allowed.system.users property. </p>
</li>

                    </ul>

                </div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">If YARN is configured to use Kerberos authentication, configure <span class="ph">Data
                  Collector</span> to use Kerberos authentication. </span>
                <div class="itemgroup info">When you configure Kerberos authentication for <span class="ph">Data
                  Collector</span>, you enable <span class="ph">Data
                  Collector</span> to use Kerberos and define the principal and keytab. <p class="p">When Kerberos is
                        enabled for <span class="ph">Data
                  Collector</span>, <span class="ph">Data
                  Collector</span> automatically uses the Kerberos principal and keytab to connect to any
                        YARN cluster that uses Kerberos. </p>
<p class="p">For more information, see <a class="xref" href="../Install_Config/DCConfig.html#concept_hnm_n4l_xs" title="You can use Kerberos authentication to connect to external systems as well as YARN clusters.">Enabling Kerberos Authentication</a>.</p>
</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the pipeline properties, on the <span class="keyword wintitle">General</span> tab, set the
                        <span class="ph uicontrol">Execution Mode</span> property to <span class="ph uicontrol">Cluster
                        Batch</span>.</span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">On the <span class="ph uicontrol">Cluster</span> tab, enter the required properties to
                    read from HDFS. </span>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">In the pipeline, use the Hadoop FS origin for cluster mode.</span>
                <div class="itemgroup info">On the <span class="keyword wintitle">General</span> tab of the origin, select the appropriate
                    CDH or HDP stage library for cluster mode.</div>
            </li>
<li class="li step stepexpand">
                <span class="ph cmd">If YARN is configured to use Kerberos authentication, in the origin, enable the
                        <span class="ph uicontrol">Kerberos Authentication</span> property on the
                        <span class="keyword wintitle">Hadoop FS</span> tab. </span>
            </li>
</ol>

    </div>

    <div class="related-links"><div class="relinfo"><strong>Related information</strong><br xmlns="http://www.w3.org/1999/xhtml" />
<div class="related_link"><a class="navheader_parent_path" href="../Pipeline_Configuration/ConfiguringAPipeline.html#task_xlv_jdw_kq" title="Configure a pipeline to define the stream of data. After you configure the pipeline, you can start the pipeline.">Configuring a Pipeline</a></div>
<div class="related_link"><a class="navheader_parent_path" href="../Origins/HadoopFS-origin.html#concept_lw2_tnm_vs" title="The Hadoop FS origin reads data from the Hadoop Distributed File System (HDFS). Use this origin only in pipelines configured for cluster execution mode.">Hadoop FS</a></div>
</div>
</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Cluster_Mode/ClusterPipelines_title.html" title="Cluster Pipelines"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Cluster Pipelines</span></a></span>  </div><div class="footer"><!-- SDC google analytics --><script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-60917135-3', 'auto');
  ga('send', 'pageview');
</script></div>
</body>
</html>

<!DOCTYPE html
  SYSTEM "about:legacy-compat">
<html xml:lang="en-us" lang="en-us">
<head><meta name="description" content="You can configure error record handling at the stage level and at a pipeline level. When an error occurs while processing a record, the Data Collector handles the record based on the stage ..."></meta><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><meta name="copyright" content="(C) Copyright 2005"></meta><meta name="DC.rights.owner" content="(C) Copyright 2005"></meta><meta name="DC.Type" content="concept"></meta><meta name="DC.Title" content="Error Record Handling"></meta><meta name="abstract" content="You can configure error record handling at the stage level and at a pipeline level."></meta><meta name="description" content="You can configure error record handling at the stage level and at a pipeline level."></meta><meta name="DC.Relation" scheme="URI" content="../Pipeline_Configuration/PipelineConfiguration_title.html"></meta><meta name="DC.Format" content="XHTML"></meta><meta name="DC.Identifier" content="concept_pm4_txm_vq"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/commonltr.css"><!----></link><title>Error Record Handling</title><meta http-equiv="Content-Type" content="text/html; charset=utf-8"></meta><link rel="stylesheet" type="text/css" href="../oxygen-webhelp/resources/css/webhelp_topic.css"><!----></link><link rel="stylesheet" type="text/css" href="../skin.css"></link><script type="text/javascript"><!--
          
          var prefix = "../index.html";
          
          --></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-1.8.2.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.cookie.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery-ui.custom.min.js"><!----></script><script type="text/javascript" src="../oxygen-webhelp/resources/js/jquery.highlight-3.js"><!----></script><script type="text/javascript" charset="utf-8" src="../oxygen-webhelp/resources/js/webhelp_topic.js"><!----></script></head>
<body onload="highlightSearchTerm()" class="frmBody">
<table class="nav"><tbody><tr><td colspan="2"><div id="printlink"><a href="javascript:window.print();" title="Print this page"></a></div><div id="permalink"><a href="#" title="Link to this page"></a></div></td></tr><tr><td width="75%"><a class="navheader_parent_path" href="../Pipeline_Configuration/PipelineConfiguration_title.html" title="Pipeline Configuration">Pipeline Configuration</a></td><td><div class="navheader">
<span class="navparent"><a class="link" href="../Pipeline_Configuration/PipelineConfiguration_title.html" title="Pipeline Configuration"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Pipeline Configuration</span></a></span>  </div></td></tr></tbody></table>
<div class="nested0" id="concept_pm4_txm_vq">
  <h1 class="title topictitle1">Error Record Handling</h1>

  
  <div class="body conbody"><p class="shortdesc">You can configure error record handling at the stage level and at a pipeline level. </p>

    <p class="p">When an error
      occurs while processing a record, the <span class="ph">Data
                  Collector</span>handles the
      record based on the stage configuration. One of the stage options is to pass the record to the
      pipeline for error handling. When you select that option, the <span class="ph">Data
                  Collector</span> processes
      the record based on the pipeline error record handling configuration. </p>

    <p class="p">When you configure a pipeline, be aware that stage error handling takes precedence over
      pipeline error handling. That is, a pipeline might be configured to write error records to
      file, but if a stage is configured to discard error records, those records are not passed to
      the pipeline. Use this functionality to determine the types of error records to save for
      review and reprocessing. </p>

    <p class="p">
      
    </p>

  </div>

<div class="related-links"></div>
<div class="topic concept nested1" id="concept_atr_j4y_5r">
 <h2 class="title topictitle2">Stage Error Record Handling</h2>

 
 <div class="body conbody"><p class="shortdesc">Most stages include error record handling options. When an error occurs when processing
    a record, the <span class="ph">Data
                  Collector</span> processes
    records based on the stage error record handling property, <span class="ph uicontrol">On Record
      Error</span>. </p>

  <div class="p">Stages include the
      following error handling options:<dl class="dl">
        
          <dt class="dt dlterm">Discard</dt>

          <dd class="dd">The stage silently discards the record. The <span class="ph">Data
                  Collector</span> does
            not log information about the error or note the specific record that encountered an
            error. The discarded record is not included in Monitor mode error record counts or
            metrics. </dd>

        
        
          <dt class="dt dlterm">Send to Error </dt>

          <dd class="dd">The stage sends the record to the pipeline for error handling. The pipeline processes
            the record based on the pipeline error handling configuration.</dd>

          <dd class="dd">When you monitor the pipeline, you can view the most recent set of error records and
            information about the errors on the Error Records tab for the stage. But this
            information becomes unavailable after you stop the pipeline. </dd>

        
        
          <dt class="dt dlterm">Stop Pipeline</dt>

          <dd class="dd">The <span class="ph">Data
                  Collector</span>
            stops the pipeline and logs information about the error. The error that stopped the
            pipeline displays as an alert in Monitor mode and as an error in the pipeline history.
          </dd>

        
      </dl>
</div>

 </div>

</div>
<div class="topic concept nested1" id="concept_kgc_l4y_5r">
 <h2 class="title topictitle2">Pipeline Error Record Handling</h2>

 
 <div class="body conbody"><p class="shortdesc">Pipeline error record handling determines how the <span class="ph">Data
                  Collector</span> processes
    error records that stages send to the pipeline for error handling, as well as records
    deliberately dropped from the pipeline such as those without required fields.</p>

  <div class="p">The pipeline
      provides the following error record handling options:<dl class="dl">
        
          <dt class="dt dlterm">Discard</dt>

          <dd class="dd">The pipeline silently discards the record. The <span class="ph">Data
                  Collector</span> does
            not log information about the error or note the specific record that encountered an
            error. The discarded record is not included in error record counts or metrics available
            in monitor mode. </dd>

        
        
          <dt class="dt dlterm">Write to File</dt>

          <dd class="dd">The pipeline writes error records and related details to a local directory. The <span class="ph">Data
                  Collector</span>
            includes the records in error record counts and metrics.</dd>

          <dd class="dd">You specify the directory to use and the maximum file size. Error files are named as
            follows: <samp class="ph codeph">records-&lt;file number&gt;.json.</samp></dd>

        
        
          <dt class="dt dlterm">Write to Kafka</dt>

          <dd class="dd">The pipeline writes error records and related details to Kafka. The <span class="ph">Data
                  Collector</span>
            includes the records in error record counts and metrics.</dd>

          <dd class="dd">You specify the configuration properties for the Kafka cluster that you want to use.
          </dd>

        
      </dl>
</div>

  <p class="p">When a <span class="ph">Data
                  Collector</span>
   encounters an unexpected error, it stops the pipeline and logs the error.</p>

 </div>

</div>
<div class="topic concept nested1" id="concept_y4z_n4y_5r">
 <h2 class="title topictitle2">Example</h2>

 
 <div class="body conbody"><p class="shortdesc"></p>

  <p class="p">A Kafka Consumer origin stage reads JSON data with a maximum object length of 4096 characters
   and the stage encounters an object with 5000 characters. Based on stage error handling
   configuration, the <span class="ph">Data
                  Collector</span> either
   discards the record, stops the pipeline, or passes the record to the pipeline for error handling. </p>

  <div class="p">When the stage is configured to send the record to the pipeline, one of the following occurs
   based on how you configure the pipeline error handling: <ul class="ul" id="concept_y4z_n4y_5r__ul_a3h_mjy_5r">
    <li class="li">When the pipeline discards error records, the <span class="ph">Data
                  Collector</span> discards the
     record without noting the action or the cause. <p class="p">When you monitor the pipeline, you can view
      the most recent set of error records and information about the errors on the Error Records tab
      for the stage. But this information becomes unavailable after you stop the pipeline. </p>
</li>

    <li class="li">When the pipeline writes error records to file or Kafka, the <span class="ph">Data
                  Collector</span> writes the
     error record and additional error information to the file or Kafka, respectively. It also
     includes the error records in monitor counts and metrics. </li>

   </ul>
</div>

  <p class="p"></p>

 </div>

</div>
<div class="topic task nested1" id="task_skc_j54_1r">
    <h2 class="title topictitle2">Reprocessing Error Records</h2>

    
    <div class="body taskbody"><p class="shortdesc">You can use a Directory or Kafka Consumer origin in a error pipeline to reprocess
        error record files. When you reprocess error record files, do not edit or rename the files.
        The origin expects the files as generated by the original pipeline.</p>

        <div class="section context">
            <p class="p">In the error
                pipeline, include the Directory or Kafka Consumer origin and configure it to use the
                SDC Records data format. The SDC Records data format provides information for
                reprocessing the original records with the necessary error handling. </p>

            <div class="p">The SDC Records data format provides the following information: <ul class="ul" id="task_skc_j54_1r__ul_fxk_mbd_br">
                    <li class="li">The original source record, as read by the pipeline that generated the
                        error. Changes to the record that might have occurred within the original
                        pipeline are not preserved.</li>

                    <li class="li">Additional metadata that includes: <ul class="ul" id="task_skc_j54_1r__ul_xqh_2bg_cr">
                            <li class="li">The path the record took through the pipeline, including the stage
                                that discarded the record.</li>

                            <li class="li">Information about the error, including the error code and
                                message.</li>

                        </ul>
</li>

                </ul>
</div>

            <p class="p">When you create the error pipeline, you can use error and record functions provided
                by the expression language to route different types of error records through
                different transformation logic to resolve the error and write the corrected record
                to destinations. </p>

            <p class="p">For example, your error files contain records with invalid product IDs discarded as a
                required field from the first processor in the pipeline, a Field Filter. They also
                include records discarded by a Field Converter for attempting an invalid data type
                conversion. </p>

            <p class="p">In the error pipeline, you can use a Stream Selector to route the records discarded
                from the Field Filter to a branch that corrects product IDs, and the records
                discarded by the Field Converter to a branch that performs a valid data type
                conversion. </p>

        </div>

    </div>

</div>
</div>
<div class="navfooter"><!---->
<span class="navparent"><a class="link" href="../Pipeline_Configuration/PipelineConfiguration_title.html" title="Pipeline Configuration"><span class="navheader_label">Parent topic</span><span class="navheader_separator">: </span><span class="navheader_linktext">Pipeline Configuration</span></a></span>  </div><div class="footer"><div> </div><!-- © <a href="http://creativecommons.org/licenses/by-nc/4.0/legalcode">CC BY-NC 4.0.</a> StreamSets, 2015. --></div>
</body>
</html>
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_pm4_txm_vq">
 <title>Error Handling</title>
 <shortdesc>You can configure the default error handling for a pipeline. Some stages include error
  handling properties that override the pipeline default. When a <ph
   conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> encounters an
  unexpected error, it stops the pipeline. </shortdesc>
 <conbody>
  <p><indexterm>error
     handling<indexterm>overview</indexterm></indexterm><indexterm>pipelines<indexterm>error
     handling</indexterm></indexterm>You can configure a pipeline to discard error records or to
   save error records. When you save error records, you define the directory to use and when to
   create additional files. Error files are written to the directory with the following naming
   convention: records-&lt;file number>.json.</p>
  <p>Each stage in the pipeline includes built-in resilience. Some stages also include configurable
   error handling. When a stage without explicit error handling options encounters an error record,
   the <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> uses
   the default error handling for the pipeline.</p>
  <p>For example, when a Kafka Consumer origin stage reads JSON data with a maximum object length of
   4096 characters and the stage encounters an object with 5000 characters, the stage discards or
   saves the object based on the pipeline error handling configuration. </p>
  <p>When a stage includes an error handling option, the stage configuration can override the
   pipeline configuration. </p>
  <p>For example, a Field Splitter splits field values into three parts and is configured to discard
   records that cannot be split. Even if the pipeline is configured to save error records, the Field
   Splitter stage discards any record that cannot be split as requested. </p>
 </conbody>
</concept>

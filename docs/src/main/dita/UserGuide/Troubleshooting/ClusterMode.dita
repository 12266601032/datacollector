<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_zjl_nnl_2s">
 <title>Cluster Mode </title>
 <conbody>
  <p><indexterm>troubleshooting<indexterm>cluster mode</indexterm></indexterm>Use the following tips
      for help with cluster mode:<dl>
        <dlentry>
          <dt>Why isn't the <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
            reading data from my new partition?</dt>
          <dd>If you create a new partition in the Kafka topic, to launch a new <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
            worker to read from the partition, you need to restart the pipeline.</dd>
        </dlentry>
        <dlentry>
          <dt>My pipeline fails to start with the following error: </dt>
          <dd><codeblock>VALIDATION_0072 - Data collector is in standalone mode, cannot run pipeline cluster mode.</codeblock>Though
            the pipeline is configured for cluster mode, the <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> is
            not. To configure the <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> to
            run in cluster mode, in the <ph
              conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
            configuration file, set the <uicontrol>sdc.execution.mode</uicontrol> property to
            "cluster".</dd>
        </dlentry>
        <dlentry>
          <dt>My pipeline fails to start with the following error: </dt>
          <dd><codeblock>Error starting application: java.util.concurrent.ExecutionException: java.lang.IllegalStateException: 
Process submitting the spark job is dead and couldn't retrieve the YARN application id.</codeblock>Check
            the Spark on YARN logs for more information. It's possible that the Spark on YARN client
            configuration is not in place, the node is not a gateway node, or the installation is
            out of date.<draft-comment author="Loretta">are these correct? reworded from original
              email.</draft-comment></dd>
        </dlentry>
        <dlentry>
          <dt>My pipeline stopped unexpectedly.</dt>
          <dd>Check the Spark Application Master logs in the YARN ResourceManager UI for more
            information about the problem.</dd>
        </dlentry>
        <dlentry>
          <dt>Why does my pipeline take so long to start?</dt>
          <dd>The start time for a pipeline can vary based on how busy the YARN cluster is.
            Typically, a cluster pipeline should start in 30-90 seconds. </dd>
        </dlentry>
      </dl></p>
 </conbody>
</concept>

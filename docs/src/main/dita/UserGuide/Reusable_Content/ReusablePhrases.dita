<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_vhs_5tz_xp">
      <title>Reusable phrases for the book</title>
      <shortdesc>Use the following reusable phrases for conrefs in the book:<draft-comment
                  author="Loretta">Company name - not really using this</draft-comment></shortdesc>
      <conbody>
            <p>Company name: <ph id="company">StreamSets</ph></p>
            <draft-comment author="Loretta">product name: trying to consistently use
                  this</draft-comment>
            <p>Full, init cap version of the product name: <ph id="pName-long">Data
                  Collector</ph></p>
            <draft-comment author="Loretta">Using this in all DC Console topics:</draft-comment>
            <p>
                  <note id="Note-OptionDispay">Some buttons and options might not display in the
                        console. The items that display are based on the task that you are
                        performing and roles assigned to your user account. </note>
            </p>
            <p>
                  <draft-comment author="Loretta">
                        <p>The following bullets are used in "Previewing a Single Stage" and
                              "Troubleshooting":</p>
                  </draft-comment>
            </p>
            <ul id="ul_EditPreview">
                  <li>The output data column for an origin.</li>
                  <li>The input data column for processors.</li>
            </ul>
            <p>
                  <draft-comment author="Loretta">The following bullets are the types of origins
                        that can be reset / that remember where you left off. These are used
                        currently in "Starting a Pipeline" and "Resetting an
                        Origin":</draft-comment>
                  <ul id="ul_saveOffset">
                        <li>Directory</li>
                        <li>Kafka Consumer</li>
                  </ul>
            </p>
            <p>
                  <draft-comment author="Loretta">The following bullets are CSV file types. Used in
                        "Configuring a Directory Origin" and "Configuring the Kafka
                        Consumer"</draft-comment>
            </p>
            <p>
                  <ul id="ul_delFileTypes">
                        <li><uicontrol>Default CSV</uicontrol> - File that includes comma-separated
                              values. Ignores empty lines in the file.</li>
                        <li><uicontrol>RFC4180 CSV</uicontrol> - Comma-separated file that strictly
                              follows RFC4180 guidelines.</li>
                        <li><uicontrol>MS Excel CSV</uicontrol> - Microsoft Excel comma-separated
                              file.</li>
                        <li><uicontrol>MySQL CSV</uicontrol> - MySQL comma separated file.</li>
                        <li><uicontrol>Tab-Separated Values</uicontrol> - File that includes
                              tab-separated values.</li>
                  </ul>
            </p>
            <draft-comment author="Loretta">Use the following for invoking the expression editor. So
                  far, using in Config Expression Evaluator, Config Stream Selector, and Expression
                  Editor:</draft-comment>
            <p id="EEditor">Optionally, click <uicontrol>Ctrl + Spacebar</uicontrol> to invoke
                  expression completion for help with creating the expression. </p>
            <p>
                  <draft-comment author="Loretta">Using the following in the Configuring topic for
                        several processors (Expression Evaluator, Field Converter, Field Hasher,  -
                        whichever ones allow wildcard use:</draft-comment>
            </p>
            <p id="wildcard">You can use the asterisk wildcard to represent array indices and map
                  elements. <xref href="../Processors/WildcardsArraysMaps.dita#concept_vqr_sqc_wr"
                              ><image href="../Graphics/icon_moreInfo.png" scale="10"/>
                  </xref>
            </p>
            <p>
                  <draft-comment author="Loretta">The following list is destination data formats.
                        Used by Kafka, Hadoop FS, and Flume.</draft-comment>
                  <dl id="DataFormats-dest">
                        <dlentry>
                              <dt>Text</dt>
                              <dd>The destination writes a single text field of a record. When you
                                    configure the stage, you select the field to use. When
                                    necessary, merge record data into the field earlier in the
                                    pipeline. </dd>
                        </dlentry>
                        <dlentry>
                              <dt>JSON</dt>
                              <dd>The destination writes records as JSON data. You can use one of
                                    the following formats:<ul id="ul_dd1_5y1_wr">
                                          <li>Array - Each file includes a single array. In the
                                                array, each element is a JSON representation of each
                                                record.</li>
                                          <li>Multiple objects - Each file includes multiple JSON
                                                objects. Each object is a JSON representation of a
                                                record. </li>
                                    </ul></dd>
                        </dlentry>
                        <dlentry>
                              <dt>Delimited</dt>
                              <dd>The destination writes records as delimited data. When you use
                                    this data format, you must ensure that the data uses the
                                    following data structure:<ul id="ul_tr1_ms1_wr">
                                          <li>A root field that contains an array of maps.</li>
                                          <li>Each map includes a <term>value</term> element and an
                                                optional <term>header</term> element.</li>
                                    </ul></dd>
                        </dlentry>
                        <dlentry>
                              <dt>SDC Record</dt>
                              <dd>The destination writes records in the SDC Record data format.
                              </dd>
                        </dlentry>
                  </dl>
            </p>
      </conbody>
</concept>

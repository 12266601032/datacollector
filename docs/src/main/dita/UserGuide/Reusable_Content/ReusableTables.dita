<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_wfr_rnw_yq">
 <title>Reusable Tables of Information</title>
 <shortdesc></shortdesc>
 <conbody>
  <p>
   <draft-comment author="Loretta">The following IgnoreControlChar-row is used in Configuring a -
    Directory, File Tail, Kafka Consumer, Kinesis Consumer, JSON Parser, Log
    Parser:]</draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table_mxl_xrm_js">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <tbody>
      <row id="IgnoreControlChars-row">
       <entry>Ignore Ctrl Characters <xref href="../Pipeline_Design/ControlCharacters.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" placement="inline"
          id="image_xwx_xrm_js"/></xref></entry>
       <entry>Removes all ASCII control characters except for the tab, line feed, and carriage
        return characters.</entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta">The following MaxBatchSize and BatchWaitTime rows are used in
    Configuring Kafka Consumer, JMS Consumer. See if they should go anywhere else.</draft-comment>
   <table frame="all" rowsep="1" colsep="1" id="table_tft_4jk_dt">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1*"/>
     <colspec colname="c2" colnum="2" colwidth="3.5*"/>
     <tbody>
      <row id="MaxBatchSize">
       <entry>Max Batch Size (records)</entry>
       <entry>Maximum number of records processed at one time. Honors values up to the <ph
         conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> maximum
        batch size. <p>Default is 1000. The <ph
          conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> default
         is 1000.</p></entry>
      </row>
      <row id="BatchWaitTime">
       <entry>Batch Wait Time (ms) <xref href="../Origins/BatchSizeWaitTime.dita#concept_ypd_vgr_5q">
         <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_mgp_2q3_br"
          placement="inline"/></xref></entry>
       <entry>Number of milliseconds to wait before sending a partial or empty batch. </entry>
      </row>
      <row id="MessagesCharset">
       <entry>Messages Charset</entry>
       <entry>Character encoding of the messages to be processed.<p>Not used for the SDC Record,
         Avro, or Binary data format.</p></entry>
      </row>
      <row id="Charset">
       <entry>Charset</entry>
       <entry>Character encoding of the messages to be processed.<p>Not used for the SDC Record or
         Avro data format.</p></entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
  <p>
   <draft-comment author="Loretta">The following rows are used in the Data Collector Console -
    Overview, </draft-comment>
  </p>
  <simpletable>
   <strow id="Icon-Help">
    <stentry><image href="../Graphics/icon_OverCHelp.png" id="image_bkz_wk3_ts"/></stentry>
    <stentry>Help icon</stentry>
    <stentry>Provides context-sensitive help based on the information in the panel. </stentry>
   </strow>
  </simpletable>
  <p>
   <draft-comment author="Loretta">The following row is used in Configuring Hive Streaming and
    Configuring JDBC Producer</draft-comment>
  </p>
  <table frame="all" rowsep="1" colsep="1" id="table_ps1_hln_jt">
   <tgroup cols="2">
    <colspec colname="c1" colnum="1" colwidth="1.5*"/>
    <colspec colname="c2" colnum="2" colwidth="3.5*"/>
    <thead>
     <row>
      <entry/>
      <entry/>
     </row>
    </thead>
    <tbody>
     <row id="FIELD2ColumnMapping">
      <entry>Field to Column Mapping</entry>
      <entry>
       <p>Use to override the default field to column mappings. </p>
       <p>By default, fields are written to columns of the same name. </p>
      </entry>
     </row>
    </tbody>
   </tgroup>
  </table>
  <p>
   <draft-comment author="Loretta">The following table is used in full for the Amazon S3 origin and
    the Amazon S3 destination reuses individual rows. File Compression row is also used in Directory
    configuring.</draft-comment>
  </p>
  <p>
   <table frame="all" rowsep="1" colsep="1" id="AmazonS3-oProps">
    <tgroup cols="2">
     <colspec colname="c1" colnum="1" colwidth="1*"/>
     <colspec colname="c2" colnum="2" colwidth="2.57*"/>
     <thead>
      <row>
       <entry>File Property</entry>
       <entry>Description</entry>
      </row>
     </thead>
     <tbody>
      <row id="S3-Region">
       <entry>Region</entry>
       <entry>Amazon S3 region. </entry>
      </row>
      <row id="S3AccessKeyId">
       <entry>Access Key ID</entry>
       <entry>Amazon S3 access key ID.</entry>
      </row>
      <row id="S3SecretAccessKey">
       <entry>Secret Access Key</entry>
       <entry>Amazon S3 secret access ID.</entry>
      </row>
      <row id="S3Bucket">
       <entry>Bucket</entry>
       <entry>Bucket where the data resides.</entry>
      </row>
      <row id="S3Folder">
       <entry>Folder</entry>
       <entry>Optional folder where the data resides. If used with a file name pattern, acts as a
        root folder for the file name pattern and any directory included in the file name pattern.
         <p>To read data from more than one folder, use glob patterns to represent the directory
         structure in the file naming pattern. </p></entry>
      </row>
      <row id="S3ObjectPathDelimiter">
       <entry>Object Path Delimiter</entry>
       <entry>Delimiter used by Amazon S3 to define the directory structure.<p>Default is slash ( /
         ).</p></entry>
      </row>
      <row>
       <entry>File Name Pattern <xref href="../Origins/AmazonS3-Folder_FileNamePattern.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_tfr_bk5_ht"/>
        </xref></entry>
       <entry>
        <p>Regular expression that describes the pattern of the file names to process. You can use
         UNIX-style wildcards, such as * or ?. For example, *.log. </p>
        <p>To process data in more than one folder, you can include the path to the files to be
         processed and use wildcards to define glob patterns. </p>
       </entry>
      </row>
      <row>
       <entry>Buffer Limit (KB)</entry>
       <entry>Maximum buffer size. The buffer size determines the size of the record that can be
        processed. <p>Decrease when memory on the <ph
          conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> machine
         is limited. Increase to process larger records when memory is available. </p><p>Default is
         64000.</p></entry>
      </row>
      <row>
       <entry>Max Batch Size (records)</entry>
       <entry>
        <p>Number of records to pass through the pipeline at one time. Honors values up to the Data
         Collector maximum batch size. </p>
        <p>Default is 1000. The Data Collector default is 1000. </p>
       </entry>
      </row>
      <row>
       <entry>Batch Wait Time (ms) <xref href="../Origins/BatchSizeWaitTime.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" placement="inline"
          id="image_rrh_3qw_rt"/></xref></entry>
       <entry>
        <p>Number of seconds to wait before sending a partial or empty batch. </p>
       </entry>
      </row>
      <row id="S3DataFormat">
       <entry>Data Format <xref href="../Origins/AmazonS3-DataFormat.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_w4w_q3p_ht"/>
        </xref></entry>
       <entry>Data format for source files. Use one of the following formats:<ul id="ul_y1t_wql_5q">
         <li>Text</li>
         <li>JSON</li>
         <li>Log</li>
         <li>Avro</li>
         <li>Delimited</li>
         <li>SDC Record <xref href="../Pipeline_Design/SDCRecordFormat.dita#concept_qkk_mwk_br">
           <image href="../Graphics/icon_moreInfo.png" scale="10" id="image_wjh_ycl_br"
            placement="inline"/></xref></li>
         <li>XML</li>
        </ul></entry>
      </row>
      <row conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/Charset">
       <entry/>
      </row>
      <row
       conref="../Reusable_Content/ReusableTables.dita#concept_wfr_rnw_yq/IgnoreControlChars-row">
       <entry/>
      </row>
      <row id="Origin-FileCompression">
       <entry>Compression Type <xref href="../Origins/FileCompressionTypes.dita">
         <image href="../Graphics/icon_moreInfo.png" scale="10" placement="inline"
          id="image_xqq_yv4_c5"/></xref></entry>
       <entry>The compression type of the files:<ul id="ul_vph_jp2_qs">
         <li>None - Processes only uncompressed files.</li>
         <li>Compressed File - Processes files compressed by the supported compression formats.</li>
         <li>Archive - Processes files archived by the supported archive formats.</li>
         <li>Compressed Archive - Processes files archived and compressed by the supported archive
          and compression formats.</li>
        </ul></entry>
      </row>
     </tbody>
    </tgroup>
   </table>
  </p>
 </conbody>
</concept>

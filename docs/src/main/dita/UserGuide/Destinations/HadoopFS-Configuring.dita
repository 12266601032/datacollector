<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE task PUBLIC "-//OASIS//DTD DITA General Task//EN" "generalTask.dtd">
<task id="task_m2m_skm_zq">
    <title>Configuring a Hadoop FS Destination</title>
    <taskbody>
        <context>
            <p><indexterm>Hadoop FS
                destination<indexterm>configuring</indexterm></indexterm>Configure a Hadoop FS
                destination to write data to a Hadoop file system.</p>
        </context>
        <steps id="steps_ljw_44d_br">
            <step
                conref="../Reusable_Content/ReusableSteps.dita#task_kzs_5vz_sq/1stStep-StageLib-ReqField-EHandling">
                <cmd/>
            </step>
            
            <step>
                <cmd>On the <wintitle>Hadoop FS</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_rst_t4d_br">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1*"/>
                            <colspec colname="c2" colnum="2" colwidth="2.85*"/>
                            <thead>
                                <row>
                                    <entry>Hadoop FS Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Hadoop FS URI</entry>
                                    <entry>URI of the Hadoop file system.</entry>
                                </row>
                                <row>
                                    <entry>Kerberos Authentication</entry>
                                    <entry>Indicates that the Hadoop file system uses Kerberos
                                        authentication.</entry>
                                </row>
                                <row>
                                    <entry>Kerberos Principal</entry>
                                    <entry>Kerberos principal used to connect to the Hadoop file
                                        system.</entry>
                                </row>
                                <row>
                                    <entry>Kerberos Keytab</entry>
                                    <entry>Location for the keytab file that contains the
                                        credentials for the Kerberos principal.</entry>
                                </row>
                                <row>
                                    <entry>Hadoop FS Configuration</entry>
                                    <entry>Additional Hadoop configuration properties to use. <p>To
                                            add properties, click <uicontrol>Add</uicontrol> and
                                            define the Hadoop property name and value. Use the
                                            property names and values as expected by
                                        Hadoop.</p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>On the <wintitle>Output Files</wintitle> tab, configure the following
                    options:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_byd_xpd_br">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1*"/>
                            <colspec colname="c2" colnum="2" colwidth="2.89*"/>
                            <thead>
                                <row>
                                    <entry>Output Files Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Data Format</entry>
                                    <entry>Format of data to be written. Use one of the following
                                            options:<ul id="ul_un2_cqd_br">
                                            <li>JSON</li>
                                            <li>Delimited</li>
                                            <li>SDC Record <xref
                                                  href="../Pipeline_Configuration/SDCRecordFormat.dita#concept_qkk_mwk_br">
                                                  <image href="../Graphics/icon_moreInfo.png"
                                                  scale="10" id="image_wjh_ycl_br"/></xref></li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>File Type</entry>
                                    <entry>Output file type:<ul id="ul_lgf_j3g_br">
                                            <li>Text files</li>
                                            <li>Sequence files</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>On Record Error</entry>
                                    <entry>Determines how to handle error records:<ul
                                            id="ul_o2f_4q3_cr">
                                            <li>Discard - Discards the record.</li>
                                            <li>Send to Error - Sends the record to the pipeline for
                                                error handling.</li>
                                            <li>Stop Pipeline - Stops the pipeline.</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Files Prefix</entry>
                                    <entry>Prefix to use for output files. Use when writing to a
                                        directory that receives files from other sources.</entry>
                                </row>
                                <row>
                                    <entry>Directory Template <xref
                                            href="HadoopFS-DirectoryTemplates.dita#concept_cvc_skd_br">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                                id="image_c4p_p5v_yq"/></xref></entry>
                                    <entry>Template for creating output directories. You can use
                                        constants, field values, and datetime variables. <p>Output
                                            directories are created based on the smallest datetime
                                            variable in the template.</p></entry>
                                </row>
                                <row>
                                    <entry>Data Time Zone</entry>
                                    <entry>Time zone to use to create directories and evaluate where
                                        records are written.</entry>
                                </row>
                                <row>
                                    <entry>Time Basis <xref
                                            href="HadoopFS-TimeBasis.dita#concept_gkz_smd_br">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                            /></xref></entry>
                                    <entry>Time basis to use for creating output directories and
                                        writing records to the directories. Use one of the following
                                            expressions:<ul id="ul_ggs_43g_br">
                                            <li>${time:now()} - Uses the processing time as the time
                                                basis. </li>
                                            <li>${record:value("/&lt;date field>") - Uses the time
                                                associated with the record as the time basis.</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Max Records in a File</entry>
                                    <entry>Maximum number of records to be written to an output
                                        file. Additional records are written to a new file. <p>Use 0
                                            to opt out of this property.</p></entry>
                                </row>
                                <row>
                                    <entry>Max File Size (MB)</entry>
                                    <entry>Maximum size of an output file. Additional records are
                                        written to a new file. <p>Use 0 to opt out of this
                                            property.</p></entry>
                                </row>
                                <row>
                                    <entry>Compression Codec</entry>
                                    <entry>Program to use to compress output files:<ul
                                            id="ul_ltx_djg_br">
                                            <li>None </li>
                                            <li>gzip</li>
                                            <li>bzip2</li>
                                            <li>Snappy</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Sequence File Key</entry>
                                    <entry>Record key for creating Hadoop sequence files. Use one of
                                        the following options:<ul id="ul_xzr_vkg_br">
                                            <li>${record:value("/&lt;field name>")}</li>
                                            <li>${uuid()}</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Compression Type</entry>
                                    <entry>Compression type for sequence files when using a
                                        compression codec:<ul id="ul_etm_1lg_br">
                                            <li>Block Compression</li>
                                            <li>Record Compression</li>
                                        </ul></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>On the <wintitle>Late Records</wintitle> tab, configure the following
                    properties:</cmd>
                <info>
                    <note>These properties are relevant for a time basis based on the time of a
                        record.</note>
                    <table frame="all" rowsep="1" colsep="1" id="table_wv3_xzd_br">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1*"/>
                            <colspec colname="c2" colnum="2" colwidth="2.49*"/>
                            <thead>
                                <row>
                                    <entry>Late Records Property <xref
                                            href="HadoopFS-LateRecordHandling.dita#concept_xgm_g4d_br">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"/>
                                        </xref>
                                    </entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>Late Record Time Limit (secs)</entry>
                                    <entry>Time limit for output directories to accept data. <p>You
                                            can enter a time in seconds, or use the expression to
                                            enter a time in hours. You can also use MINUTES in the
                                            default expression to define the time in minutes.
                                        </p></entry>
                                </row>
                                <row>
                                    <entry>Late Record Handling</entry>
                                    <entry>Determines how to handle late records:<ul
                                            id="ul_gx4_c12_br">
                                            <li>Send to error - Sends the record to the pipeline for
                                                error handling. </li>
                                            <li>Send to late records file - Sends the record to a
                                                late records file.</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Late Record Directory Template <xref
                                            href="HadoopFS-DirectoryTemplates.dita#concept_cvc_skd_br">
                                            <image href="../Graphics/icon_moreInfo.png" scale="10"
                                            /></xref></entry>
                                    <entry>Template for creating late record directories. You can
                                        use constants, field values, and datetime variables.
                                            <p>Output directories are created based on the smallest
                                            datetime variable in the template.</p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
            <step>
                <cmd>For delimited data, on the <wintitle>Delimited</wintitle> tab, configure the
                    following properties:</cmd>
                <info>
                    <table frame="all" rowsep="1" colsep="1" id="table_wb3_2kg_br">
                        <tgroup cols="2">
                            <colspec colname="c1" colnum="1" colwidth="1*"/>
                            <colspec colname="c2" colnum="2" colwidth="2.53*"/>
                            <thead>
                                <row>
                                    <entry>Delimited Property</entry>
                                    <entry>Description</entry>
                                </row>
                            </thead>
                            <tbody>
                                <row>
                                    <entry>CSV Format</entry>
                                    <entry>Format for delimited data:<ul id="ul_yxk_lkg_br">
                                            <li>Basic CSV</li>
                                            <li>MS Excel CSV</li>
                                            <li>MySQL CSV</li>
                                            <li>RFC4180</li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Field Mapping</entry>
                                    <entry>Map output fields to column names for the output file.
                                        Click the <uicontrol>Add</uicontrol> icon to add additional
                                        field mappings. <ul id="ul_zgf_plg_br">
                                            <li>Field Path - Field name of the record. Use a leading
                                                slash as follows: /Field.</li>
                                            <li>Delimited Column Name - Name for the corresponding
                                                column in the output file. </li>
                                        </ul></entry>
                                </row>
                                <row>
                                    <entry>Remove New Line Characters</entry>
                                    <entry>Removes new line characters from within a record. Use
                                        True or False. <p>Recommended to ensure writing text to a
                                            Hadoop file system as a single line of text.</p></entry>
                                </row>
                            </tbody>
                        </tgroup>
                    </table>
                </info>
            </step>
        </steps>
    </taskbody>
</task>

<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_lww_3b3_kr">
 <title>Data Formats</title>
 <conbody>
  <p><indexterm>Hadoop FS destination<indexterm>data formats</indexterm></indexterm><indexterm>data
          formats<indexterm>Hadoop FS destination</indexterm></indexterm>Hadoop FS writes data to
      HDFS based on the data format that you select. You can use the following data formats:
        <draft-comment author="Loretta">copied from Reusable steps - removed SDC Record
        format.</draft-comment><dl>
        <dlentry>
          <dt>Text</dt>
          <dd>The destination writes a single text field of a record. When you configure the stage,
            you select the field to use. When necessary, merge record data into the field earlier in
            the pipeline. </dd>
        </dlentry>
        <dlentry>
          <dt>JSON</dt>
          <dd>The destination writes records as JSON data. You can use one of the following
              formats:<ul id="ul_dd1_5y1_wr">
              <li>Array - Each file includes a single array. In the array, each element is a JSON
                representation of each record.</li>
              <li>Multiple objects - Each file includes multiple JSON objects. Each object is a JSON
                representation of a record. </li>
            </ul></dd>
        </dlentry>
        <dlentry>
          <dt>Delimited</dt>
          <dd>The destination writes records as delimited data. When you use this data format, you
            must ensure that the data uses the following data structure:<ul id="ul_tr1_ms1_wr">
              <li>A root field that contains an array of maps.</li>
              <li>Each map includes a <term>value</term> element and an optional <term>header</term>
                element.</li>
            </ul></dd>
        </dlentry>
      </dl></p>
    <dl>
      <dlentry>
        <dt>Avro</dt>
        <dd>The destination writes records based on the Avro schema that you provide. The schema
          definition is included in each file.</dd>
      </dlentry>
    </dl>
 </conbody>
</concept>

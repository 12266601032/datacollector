<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_rlj_ftm_lq">
 <title>How should I use the Data Collector?</title>
 <shortdesc>Use the <ph
   conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> like a pipe in
  the data stream. Throughout your enterprise data topology, you have streams of data that you need
  to move, collect, and process on the way to their destinations. The <ph
   conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> provides the
  crucial connection between hops in the stream. </shortdesc>
 <conbody>
  <p>To solve your ingest needs, you can use a single <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> or a set
      of <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>s. For
      example, you might install a single <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> to stream
      log file data from a web server to HDFS. Or, you might install a set of <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>s to stream
      data from multiple servers into a Hadoop file system. </p>
    <p>To make things really interesting, you can use the <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> in cluster
      mode to read large volumes of data from a Kafka CDH cluster. </p>
 </conbody>
</concept>

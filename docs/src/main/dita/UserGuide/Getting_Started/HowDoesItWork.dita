<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_bl5_dl4_1r">
 <title>How does this really work?</title>
 <shortdesc>Let's walk through it...</shortdesc>
 <conbody>
  <p>After you install and launch the <ph
    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>, you access
   the <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
   console, log in, and create your first pipeline. </p>
  <p>What do you want it to do? Let's say you want to read CSV files from a directory and remove the
   newline characters before writing it to Hive. To do this, you start with a Directory origin stage
   and configure it to point to your source files. (You can also have the stage archive processed
   files and write files that were not fully processed to a separate directory for review.)</p>
  <p>To remove the newline characters, connect Directory to an Expression Evaluator processor and
   configure it to remove the newline character from the last field in the record.</p>
  <p>To write to Hive, you connect the Expression Evaluator to a Hadoop FS destination stage. You
   might configure the stage to write the data as a JSON object (though you can write it as
   delimited data as well). </p>
  <p>You preview data to view source data move through the pipeline and notice that some fields have
   missing data. So you add a Value Replacer to replace null values in those fields. </p>
  <p>Now that the data flow is done, you configure the pipeline to save records that cannot be
   processed correctly and configure an email alert to let you know when the pipeline generates more
   than 100 bad records. Then, you start the pipeline and the <ph
    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> goes to work. </p>
  <p>The <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>
   console goes into Monitor mode and displays summary and error statistics immediately. To get a
   close look at what's going on, you take a snapshot of the pipeline so you can examine how a set
   of data passed through the pipeline. You can also inspect data - configure rules to provide
   details about data as it moves from stage to stage - and configure rule-based alerts. </p>
  <p>And what about those bad records being saved? They're saved with error details. The <ph
    conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> can move them
   to an external directory so you can create an error pipeline to reprocess that data. Voila!</p>
  <p>The <ph conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> is a
   powerful tool, but we're making it as simple as possible to use. So give it a try, click the Help
   icon for information, and call us if you need a hand. </p>
 </conbody>
</concept>

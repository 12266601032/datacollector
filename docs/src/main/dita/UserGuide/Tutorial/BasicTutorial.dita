<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_phf_cjt_ls">
 <title>Basic Tutorial</title>
 <shortdesc>The basic tutorial steps through creating a pipeline that splits data to two branches
  and merges it before writing to the destination. You'll use data prevew to check how the pipeline
  processes the data, and create a data alert before starting the pipeline. </shortdesc>
 <conbody>
  <p><indexterm>tutorial<indexterm>basic</indexterm></indexterm>Here are high level steps we'll take
   to build the basic pipeline:<ol id="ol_emy_rhp_ms">
    <li>Configure pipeline properties, primarily error handling.</li>
    <li>Add a Directory origin to represent the data to be processed. </li>
    <li>Use a Stream Selector processor to route records paid by credit card to the primary branch
     and those paid by cash to an different branch. We'll set up a Required Field and use preview
     data to discard records without a payment type.</li>
    <li>Configure a Jython Evaluator to perform custom processing that determines the credit card
     type based on the credit card number. </li>
    <li>Add a Field Masker to mask credit card information. </li>
    <li>Use an Expression Evaluator to add corresponding fields to the cash records so all records
     have the same data format in the destination. Use data preview to verify the fields to add. </li>
    <li>Merge both branches to a Hadoop FS destination.</li>
    <li>Add a data rule to alert you to invalid data.</li>
    <li>Start the pipeline.</li>
   </ol></p>
  
 </conbody>
</concept>

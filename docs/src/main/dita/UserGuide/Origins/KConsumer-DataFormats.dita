<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_xgs_nlc_wr">
 <title>Data Formats</title>
 <conbody>
  <p><indexterm>data formats<indexterm>Kafka Consumer</indexterm></indexterm><indexterm>Kafka
        Consumer origin<indexterm>data formats</indexterm></indexterm>The Kafka Consumer origin
      processes data differently based on the data format. Kafka Consumer can process the following
      types of data:<draft-comment author="Loretta">Doc reminder: Updates to this section should be
        ported over to Directory-Data Formats - the origins handle data formats similarly. 4/28/15
        Also to JMS - but be careful of the differences. 8/24/15.</draft-comment></p>
  <dl>
      <dlentry conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/OriginDF-TEXT">
        <dt/>
        <dd/>
      </dlentry>
      <dlentry>
        <dt>JSON</dt>
        <dd>Generates a record for each JSON object. You can process messages that include multiple
          JSON objects or a single JSON array.</dd>
        <dd>When an object exceeds the user-defined maximum object length, the origin processes the
          object based on the error handling configuration for the stage. </dd>
      </dlentry>
      <dlentry conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/OriginDF-DELIM">
        <dt/>
        <dd/>
      </dlentry>
      <dlentry conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/OriginDF-XML">
        <dt/>
        <dd/>
      </dlentry>
      <dlentry conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/OriginDF-SDC">
        <dt/>
        <dd/>
      </dlentry>
      <dlentry conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/OriginDF-LOG">
        <dt/>
        <dd/>
      </dlentry>
      <dlentry>
        <dt>Avro</dt>
        <dd>Generates a record for every message. </dd>
        <dd>To ensure proper data processing, indicate if the message includes an Avro schema. </dd>
        <dd>You can use the schema associated with the message or provide an alternate schema
          definition. Providing an alternate schema can improve performance.</dd>
      </dlentry>
      <dlentry>
        <dt>Binary</dt>
        <dd>Generates a record with a single byte array field at the root of the record. </dd>
        <dd>When the data exceeds the user-defined maximum data size, the origin cannot process the
          data. Because the record is not created, the origin cannot pass the record to the pipeline
          to be written as an error record. Instead, the origin generates a stage error. </dd>
      </dlentry>
    </dl>
 </conbody>
</concept>

<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_tzl_zzj_dt">
 <title>Data Formats</title>
 <conbody>
  <p><indexterm>data formats<indexterm>JMS Consumer</indexterm></indexterm><indexterm>JMS Consumer
     origin<indexterm>data formats</indexterm></indexterm>The JMS Consumer origin processes data
   differently based on the data format. JMS Consumer can process the following types of
    data:<draft-comment author="Loretta">Doc reminder: Updates to this section might need be ported
    over to Directory &amp; Kafka Consumer.  Info was copied &amp; updated from those topics for
    here. 8/24/15.</draft-comment></p>
  <p>
   <dl>
    <dlentry>
     <dt>Text</dt>
     <dd>Generates a record for each line of text. Reads text data of the BytesMessage format. </dd>
     <dd>When a line exceeds the maximum line length defined for the origin, the origin truncates
            the line. The origin adds a boolean field named Truncated to indicate if the line was
            truncated.</dd>
    </dlentry>
    <dlentry>
     <dt>JSON</dt>
     <dd>Generates a record for each JSON object. You can use JSON files that include multiple JSON
      objects or a single JSON array.</dd>
     <dd>When an object exceeds the maximum object length defined for the origin, JMS Consumer
      processes the object based on the error handling configured for the origin. </dd>
    </dlentry>
    <dlentry>
     <dt>Delimited</dt>
     <dd>Generates a record for each delimited line. You can use the following delimited format
       types:<ul id="ul_a51_wzk_5q">
       <li>Default CSV (ignores empty lines)</li>
       <li>RFC4180 CSV</li>
       <li>Microsoft Excel CSV</li>
       <li>MySQL CSV</li>
       <li>Tab-separated values</li>
      </ul></dd>
     <dd>When a record exceeds the maximum record length defined for the origin, JMS Consumer
      processes the object based on the error handling configured for the origin. </dd>
     <dd>The resulting record is a List with header and value maps. the origin can convert a file to
      a map based on the header line of the file. If the file does not include a header, the origin
      creates the map based on column number.</dd>
     <dd>For more information about the delimited data record structure, see <xref
       href="../Pipeline_Design/DelimitedDataRecordTypes.dita#concept_zcg_bm4_fs"/>.</dd>
    </dlentry>
    <dlentry>
     <dt>XML</dt>
     <dd>Generates records based on the location of the XML element that you define as the record
      delimiter. If you do not define a delimiter element, JMS Consumer treats the XML file as a
      single record.</dd>
     <dd>When a record exceeds the maximum record length defined for the origin, the origin skips
      the record and continues processing with the next record. It sends the skipped record to the
      pipeline for error handling.</dd>
    </dlentry>
    <dlentry>
     <dt>SDC Records</dt>
     <dd>Generates a record for every record. Use to process records generated by a <ph
       conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> pipeline
      using the SDC Record data format.</dd>
     <dd>For error records, JMS Consumer provides the original record as read from the origin in the
      original pipeline, as well as error information that you can use to correct the record. </dd>
     <dd>When processing error records, the origin expects the error file names and contents as
      generated by the original pipeline.</dd>
    </dlentry>
    <dlentry>
     <dt>Log</dt>
     <dd>Generates a record for every log line. </dd>
     <dd>When a line exceeds the maximum line length defined for the origin, JMS Consumer truncates
      longer lines. </dd>
     <dd>You can include the processed log line as a field in the record. If the log line is
      truncated, and you request the log line in the record, the origin includes the truncated
      line.</dd>
     <dd>You can define the log format or type to be read.</dd>
    </dlentry>
    <dlentry>
     <dt>Avro</dt>
     <dd>Generates a record for every message. </dd>
     <dd>To ensure proper data processing, indicate if the message includes an Avro schema. </dd>
     <dd>You can use the schema associated with the message or provide an alternate schema
            definition. Providing an alternate schema can improve performance.<draft-comment
              author="Loretta">Add Binary data format when ready.</draft-comment></dd>
    </dlentry>
   </dl>
  </p>
 </conbody>
</concept>

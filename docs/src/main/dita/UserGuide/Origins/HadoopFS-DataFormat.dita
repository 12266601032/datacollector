<?xml version="1.0" encoding="UTF-8"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

      http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_jx4_zym_vs">
 <title>Data Formats</title>
 <conbody>
  <p><indexterm>data formats<indexterm>Hadoop FS origins</indexterm></indexterm><indexterm>Hadoop FS
          origin<indexterm>data formats</indexterm></indexterm>The Hadoop FS origin processes data
      differently based on the data format that you select. The origin processes the following types
      of data:<draft-comment author="Loretta">copied and updated from Directory, removing invalid
        data formats</draft-comment><dl>
        <dlentry>
          <dt>Text</dt>
          <dd>Generates a record for each line in the file. </dd>
          <dd>When a line exceeds the maximum line length defined for the origin, Hadoop FS
            truncates the line. The origin adds a boolean field named Truncated to indicate if the
            line was truncated.</dd>
        </dlentry>
        <dlentry>
          <dt>JSON</dt>
          <dd>Generates a record for each JSON object. You can use JSON files that include multiple
            JSON objects or a single JSON array.</dd>
          <dd>When an object exceeds the maximum object length defined for the origin, Hadoop FS
            processes the object based on the error handling configured for the origin. </dd>
        </dlentry>
        <dlentry>
          <dt>Log</dt>
          <dd>Generates a record for every log line. </dd>
          <dd>When a line exceeds the maximum line length defined for the origin, Hadoop FS
            truncates longer lines. </dd>
          <dd>You can include the processed log line as a field in the record. If the log line is
            truncated, and you request the log line in the record, Hadoop FS includes the truncated
            line.</dd>
          <dd>You can define the log format or type to be read.</dd>
        </dlentry>
        <dlentry conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/OriginDF-DELIM">
          <dt/>
          <dd/>
        </dlentry>
        <dlentry>
          <dt>Avro</dt>
          <dd>Generates a record for every message. </dd>
          <dd>To ensure proper data processing, indicate if the message includes an Avro schema. </dd>
          <dd>You can use the schema associated with the message or provide an alternate schema
            definition. Providing an alternate schema can improve performance.</dd>
        </dlentry>
      </dl></p>
 </conbody>
</concept>

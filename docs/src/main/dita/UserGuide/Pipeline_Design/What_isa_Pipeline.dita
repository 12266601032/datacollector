<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE concept PUBLIC "-//OASIS//DTD DITA Concept//EN" "concept.dtd">
<concept id="concept_isl_w44_kq">
 <title>What is a Pipeline?</title>
 <shortdesc>A pipeline describes the flow of data from the origin system to destination systems and
    defines how to transform the data along the way. </shortdesc>
 <conbody>
  <p><indexterm>pipelines<indexterm>overview</indexterm></indexterm>You can use a single origin
      stage to represent the origin system, multiple processor stages to transform data, and
      multiple destination stages to represent destination systems. </p>
    <p>When you start a pipeline, the <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> runs the
      pipeline until you stop the pipeline or shut down the <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/>. A <ph
        conref="../Reusable_Content/ReusablePhrases.dita#concept_vhs_5tz_xp/pName-long"/> can run
      multiple pipelines.</p>
    <p>While the pipeline runs, you can monitor the pipeline to verify that the pipeline performs as
      expected. You can also define metric and data rules and alerts to let you know when certain
      thresholds are reached.</p>
    <p>To process large volumes of data from a Kafka cluster or HDFS, you can configure a pipeline
      to run in cluster execution mode. For more information, see <xref
        href="../Cluster_Mode/ClusterPipelines_title.dita#concept_fpz_5r4_vs"/>.</p>
 </conbody>
</concept>
